{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "078c2d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "# natural language toolkit\n",
    "# https://www.nltk.org/\n",
    "from nltk.corpus import stopwords \n",
    "#https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7fc793f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Article  \\\n",
      "0  Data analysis is the process of inspecting and...   \n",
      "1  The performance of a machine learning algorith...   \n",
      "2  You must have seen the news divided into categ...   \n",
      "3  When there are only two classes in a classific...   \n",
      "4  The Multinomial Naive Bayes is one of the vari...   \n",
      "\n",
      "                                               Title  \n",
      "0                  Best Books to Learn Data Analysis  \n",
      "1         Assumptions of Machine Learning Algorithms  \n",
      "2          News Classification with Machine Learning  \n",
      "3  Multiclass Classification Algorithms in Machin...  \n",
      "4        Multinomial Naive Bayes in Machine Learning  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "\n",
    "data= pd.read_csv(\"Dataset/articles.csv\" ,encoding='latin1')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99f44f2",
   "metadata": {},
   "source": [
    "#### As we are working on a NLP problem, we need to clean the textual content by removing punctuation and stopwords. Here's how we can clean the textual data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91391e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    #convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # remove punctuation\n",
    "    text = text.translate(str.maketrans('','',string.punctuation))\n",
    "    # Tokenize text \n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    #  Remove stop words \n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Lemmatize tokens\n",
    "    lemma = WordNetLemmatizer()\n",
    "    tokens = [lemma.lemmatize(word)  for word in tokens]\n",
    "    # print(tokens)\n",
    "    # join tokens to form preprocessed text\n",
    "    preprocess_text = ''.join(tokens)\n",
    "    return preprocess_text\n",
    "data['Article'] = data['Article'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9979b53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to convert the textual data into a numerical representaion . We can use text vectorizer here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8faa0049",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "x= vectorizer.fit_transform(data['Article'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c233c281",
   "metadata": {},
   "source": [
    "Now we eill use an algorithm to identify relationships between the texual data to assign topic labels . We can use the Latent Disichelet Allocation algorithm (LDA) for this task . Latent Dirichet Allocation (LDA) is a generative probabilistic algorithm used to uncover the underlying topics in a corpus of textual data. Let's use the LDA algorithm to assign topic labels :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28fc560b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=5,random_state=42)\n",
    "lda.fit(x)\n",
    "\n",
    "topic_modelling = lda.transform(x)\n",
    "\n",
    "topic_labels = np.argmax(topic_modelling,axis=1)\n",
    "data['topic_labels'] = topic_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea8e8c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Article  \\\n",
      "0  dataanalysisprocessinspectingexploringdatagene...   \n",
      "1  performancemachinelearningalgorithmparticulard...   \n",
      "2  mustseennewsdividedcategorygonewswebsitepopula...   \n",
      "3  twoclassclassificationproblemproblembinaryclas...   \n",
      "4  multinomialnaivebayesonevariantnaivebayesalgor...   \n",
      "\n",
      "                                               Title  topic_labels  \n",
      "0                  Best Books to Learn Data Analysis             1  \n",
      "1         Assumptions of Machine Learning Algorithms             3  \n",
      "2          News Classification with Machine Learning             0  \n",
      "3  Multiclass Classification Algorithms in Machin...             1  \n",
      "4        Multinomial Naive Bayes in Machine Learning             1  \n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ccdef8",
   "metadata": {},
   "source": [
    "### Summary\n",
    "Topic Modelling is a Natural Language Processing technique to uncover hidden topics from text documents. It helps identify topics of the text documents to find relationships between the content of a text document and the topic. I hope you liked this article on Topic Modelling with Machine Learning using Python. Feel free to ask valuable questions in the comments section below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf3a1ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86d0692",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
